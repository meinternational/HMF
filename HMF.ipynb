{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "HMF.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPGbi4qZhuaN+wILtVgO70U",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/meinternational/HMF/blob/main/HMF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F24J7Z8XM7nf",
        "outputId": "b8fc41be-d793-4712-a7db-91301cbd75be"
      },
      "source": [
        "!pip install tensorflow-gpu==1.15\n",
        "!pip install nilearn\n",
        "!pip install nibabel"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-gpu==1.15\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bc/72/d06017379ad4760dc58781c765376ce4ba5dcf3c08d37032eeefbccf1c51/tensorflow_gpu-1.15.0-cp37-cp37m-manylinux2010_x86_64.whl (411.5MB)\n",
            "\u001b[K     |████████████████████████████████| 411.5MB 41kB/s \n",
            "\u001b[?25hCollecting gast==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Collecting keras-applications>=1.0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 8.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15) (0.2.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15) (1.1.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15) (1.15.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15) (1.19.5)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15) (1.1.2)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15) (0.36.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15) (3.3.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15) (3.12.4)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15) (0.8.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15) (1.32.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15) (0.12.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15) (1.12.1)\n",
            "Collecting tensorflow-estimator==1.15.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/62/2ee9cd74c9fa2fa450877847ba560b260f5d0fb70ee0595203082dafcc9d/tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503kB)\n",
            "\u001b[K     |████████████████████████████████| 512kB 51.5MB/s \n",
            "\u001b[?25hCollecting tensorboard<1.16.0,>=1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 50.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow-gpu==1.15) (2.10.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.6.1->tensorflow-gpu==1.15) (54.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15) (3.3.4)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15) (1.0.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15) (3.8.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15) (3.7.4.3)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-cp37-none-any.whl size=7540 sha256=e67ed86e5737990aaa75cae571cb9a55bd2c05b30bb5d6dcd8ebc32d1af4ad1e\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
            "Successfully built gast\n",
            "\u001b[31mERROR: tensorflow 2.4.1 has requirement gast==0.3.3, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.4.1 has requirement tensorboard~=2.4, but you'll have tensorboard 1.15.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.4.1 has requirement tensorflow-estimator<2.5.0,>=2.4.0, but you'll have tensorflow-estimator 1.15.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow-probability 0.12.1 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "Installing collected packages: gast, keras-applications, tensorflow-estimator, tensorboard, tensorflow-gpu\n",
            "  Found existing installation: gast 0.3.3\n",
            "    Uninstalling gast-0.3.3:\n",
            "      Successfully uninstalled gast-0.3.3\n",
            "  Found existing installation: tensorflow-estimator 2.4.0\n",
            "    Uninstalling tensorflow-estimator-2.4.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.4.0\n",
            "  Found existing installation: tensorboard 2.4.1\n",
            "    Uninstalling tensorboard-2.4.1:\n",
            "      Successfully uninstalled tensorboard-2.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDgPvlS7E4NH"
      },
      "source": [
        "!wget https://github.com/meinternational/HMF/releases/download/v0.1/msc_input_motor_session01.npy\n",
        "!wget https://github.com/meinternational/HMF/releases/download/v0.1/msc_settings_motor_session01.npy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Qq0I21VNqP6"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.contrib.opt import ScipyOptimizerInterface\n",
        "import numpy as np\n",
        "import nibabel as nib\n",
        "from numpy.random import seed\n",
        "\n",
        "tf_f = dict()\n",
        "tf_f['tensorflow.nn.relu'] = tf.nn.relu\n",
        "tf_f['tensorflow.nn.sigmoid'] = tf.nn.sigmoid\n",
        "tf_f['tensorflow.abs'] = tf.abs\n",
        "tf_f['tensorflow.identity'] = tf.identity\n",
        "tf_f['tensorflow.tanh'] = tf.tanh\n",
        "tf_f['tensorflow.nn.softplus'] = tf.nn.softplus\n",
        "\n",
        "class Base(object):\n",
        "\n",
        "    def __init__(self, settings):\n",
        "        self.settings = settings\n",
        "        self.placeholder = self.build_placeholder()\n",
        "        self.model = self.build_model()\n",
        "        if 'lbfgsb' in self.settings and self.settings['lbfgsb']:\n",
        "            self.optimizer = ScipyOptimizerInterface(self.model['cost'], method='L-BFGS-B', options={'maxiter': self.settings['max_iter'], 'disp': True})\n",
        "        else:\n",
        "            optimizer = tf.train.AdamOptimizer()\n",
        "            self.optimizer = optimizer.minimize(self.model['cost'])\n",
        "        \n",
        "        init = tf.global_variables_initializer()\n",
        "        self.sess = tf.Session(config=tf.ConfigProto(log_device_placement=False))\n",
        "        self.sess.run(init)\n",
        "\n",
        "    def g(self, h, cost='l1'):\n",
        "        if cost=='logcosh':\n",
        "            return tf.reduce_sum( 0.5 * tf.log(tf.cosh(2*h)))\n",
        "\n",
        "        if cost=='l1':\n",
        "            return tf.reduce_sum(tf.abs(h))\n",
        "\n",
        "        if cost=='l2':\n",
        "            return tf.reduce_sum(tf.pow(h,2))\n",
        "\n",
        "        if cost=='l1_approx':\n",
        "            return tf.reduce_sum(tf.sqrt(tf.constant(10e-8) + tf.pow(h,2)))\n",
        "\n",
        "        if cost=='exp':\n",
        "            return tf.reduce_sum(-tf.exp(-tf.pow(h,2)/2.0))\n",
        "\n",
        "    def kl_divergence(self,x, y): # Kullback-Leibler divergence between two exponential distributions\n",
        "        return tf.log( x ) - tf.log( y ) + ( y / x ) - 1.0\n",
        "\n",
        "    def filter2toeplitz(self, conv_filter): # converts filter to Toeplitz matrix\n",
        "        len_h = conv_filter.get_shape().as_list()[0]\n",
        "        toplitz = list()\n",
        "        for t in range(self.settings['n_input']):\n",
        "            if t==0:\n",
        "                toplitz.append(tf.concat([conv_filter, tf.zeros(self.settings['n_input']-t-len_h)],0))\n",
        "\n",
        "            elif t>0 and (t+len_h<self.settings['n_input']):\n",
        "                toplitz.append(tf.concat([tf.zeros(t), conv_filter, tf.zeros(self.settings['n_input']-t-len_h)],0))\n",
        "\n",
        "            else:\n",
        "                toplitz.append(tf.concat([tf.zeros(t), conv_filter[0:self.settings['n_input']-t]],0))\n",
        "\n",
        "        H = tf.transpose(tf.reshape(tf.concat(toplitz,0),(self.settings['n_input'],self.settings['n_input'])))\n",
        "        return H\n",
        "\n",
        "    def toeplitz2filter(self, H): # converts Toeplitz matrix to filter\n",
        "        hw = self.settings['filter_length']/2\n",
        "        hrft = list()\n",
        "        for i,c in enumerate(range(hw,self.settings['n_input']-(hw+1))):\n",
        "            hrft.append( H[c-hw:c+hw,c] )\n",
        "\n",
        "        return tf.add_n(hrft)/(float(len(hrft)))\n",
        "\n",
        "    def build_model(self): # overwrite this function\n",
        "        pass\n",
        "\n",
        "    def build_placeholder(self):\n",
        "        placeholder = dict()\n",
        "        placeholder['x'] = tf.placeholder(tf.float32)\n",
        "        placeholder['GM'] = tf.placeholder(tf.float32)\n",
        "        placeholder['MASK'] = tf.placeholder(tf.float32)\n",
        "        if 'filter_length' in self.settings:\n",
        "            placeholder['t'] = tf.placeholder(tf.float32, [self.settings['filter_length']])\n",
        "\n",
        "        if 'H_init' in self.settings:\n",
        "            placeholder['H_mask'] = tf.placeholder(tf.float32)\n",
        "\n",
        "        return placeholder\n",
        "\n",
        "    def fit(self, input_dict):\n",
        "        feed_dict = dict()\n",
        "        for key in list(self.placeholder.keys()):\n",
        "            feed_dict[self.placeholder[key]] = input_dict[key]\n",
        "\n",
        "        self.optimizer.minimize(self.sess, feed_dict=feed_dict)\n",
        "        return self\n",
        "\n",
        "    def get_params(self, input_dict):\n",
        "        feed_dict = dict()\n",
        "        for key in list(self.placeholder.keys()):\n",
        "            feed_dict[self.placeholder[key]] = input_dict[key]\n",
        "\n",
        "        out = self.sess.run(self.model, feed_dict=feed_dict)\n",
        "        self.sess.close()\n",
        "        tf.reset_default_graph()\n",
        "        return out\n",
        "\n",
        "class CanonicalHRFMatrixFactorizationFast(Base):\n",
        "\n",
        "    def __init__(self, settings):\n",
        "        super(CanonicalHRFMatrixFactorizationFast, self).__init__(settings)\n",
        "\n",
        "    def build_model(self):\n",
        "        model = dict()\n",
        "        ######################### VARS ###################\n",
        "        model['b1'] = tf.Variable(tf.zeros([self.settings['n_hidden'], 1], dtype=tf.float32), trainable=self.settings['train_b1'])\n",
        "        model['neural'] = tf.nn.l2_normalize((tf_f[self.settings['f(neural)']](tf.get_variable(\"neural\", dtype=tf.float32, shape=[\n",
        "                                                self.settings['n_hidden'], self.settings['n_input']], initializer=tf.contrib.layers.xavier_initializer()))), 1) \n",
        "\n",
        "        model['hrf'] = tf.Variable(self.settings['hrfi'], dtype=tf.float32, trainable=self.settings['train_hrf'])\n",
        "        model['b2'] = tf.Variable(tf.zeros([self.settings['n_input'], 1], dtype=tf.float32), trainable=self.settings['train_b2'])\n",
        "        ######################## MODEL ###################\n",
        "        H = self.filter2toeplitz(model['hrf'])\n",
        "        model['bold'] = tf.transpose(tf.matmul(H, tf.transpose(model['neural'])))\n",
        "        model['h'] = self.placeholder['MASK'] * tf_f[self.settings['f(WX)']](tf.matmul(model['bold'], self.placeholder['x']) + model['b1'])\n",
        "        ######################## COST ###################\n",
        "        model['l2'] = tf.nn.l2_loss(self.placeholder['GM'] * tf.subtract((tf.matmul(tf.transpose(model['bold']), model['h']) + model['b2']), self.placeholder['x'])) / (self.settings['n_feature'])\n",
        "        cost = list()\n",
        "        cost.append(model['l2'])\n",
        "\n",
        "        if self.settings['lambda1'] > 0.0: # sparsity\n",
        "            model['rho_hat'] = tf.reduce_sum(model['h'], axis=1, keepdims=True) / self.settings['n_feature']\n",
        "            model['kl_space'] = tf.reduce_sum(self.kl_divergence(1.0/model['rho_hat'], 1.0/self.settings['mu']))\n",
        "            model['lambda1_c'] = self.settings['lambda1'] * model['kl_space']\n",
        "            cost.append(model['lambda1_c'])\n",
        "        \n",
        "        if self.settings['lambda2'] > 0.0: # total variation neural\n",
        "            model['lambda2_c'] = self.settings['lambda2'] * tf.reduce_sum(self.g(\n",
        "                model['neural'][:, 1:] - model['neural'][:, :-1], self.settings['g'])) / self.settings['n_input']\n",
        "            cost.append(model['lambda2_c'])\n",
        "\n",
        "        if self.settings['lambda2a'] > 0.0: # l1 approx neural\n",
        "            model['lambda2a_c'] = self.settings['lambda2a'] * tf.reduce_sum(self.g(model['neural'], 'l1')) / self.settings['n_input']\n",
        "            cost.append(model['lambda2a_c'])\n",
        "\n",
        "        if self.settings['lambda2b'] > 0.0: # l2 neural\n",
        "            model['lambda2b_c'] = self.settings['lambda2b'] * tf.reduce_sum(self.g(model['neural'], 'l2')) / self.settings['n_input']\n",
        "            cost.append(model['lambda2b_c'])\n",
        "\n",
        "        if self.settings['lambda3'] > 0.0: # total variation spatial\n",
        "            MASK3D = tf.reshape(self.placeholder['MASK'], self.settings['dims']+(1,))\n",
        "            H3D = tf.reshape(tf.transpose(model['h']), self.settings['dims']+(self.settings['n_hidden'],))\n",
        "\n",
        "            model['lambda3_c'] = self.settings['lambda3'] * tf.reduce_sum(self.g(MASK3D[1:, :, :, :]*(H3D[1:, :, :, :] - H3D[:-1, :, :, :]), self.settings['g'])) / self.settings['n_feature'] \\\n",
        "                                + self.settings['lambda3'] * tf.reduce_sum(self.g(MASK3D[:, 1:, :, :]*(H3D[:, 1:, :, :] - H3D[:, :-1, :, :]), self.settings['g'])) / self.settings['n_feature'] \\\n",
        "                                + self.settings['lambda3'] * tf.reduce_sum(self.g(MASK3D[:, :, 1:, :]*(H3D[:, :, 1:, :] - H3D[:, :, :-1, :]), self.settings['g'])) / self.settings['n_feature']\n",
        "\n",
        "            cost.append(model['lambda3_c']) \n",
        "\n",
        "        model['cost'] = tf.add_n(cost)\n",
        "\n",
        "        return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZBjUM6t3bOZ"
      },
      "source": [
        "settings = np.load('msc_settings_motor_session01.npy', allow_pickle=True).tolist()\n",
        "input = np.load('msc_input_motor_session01.npy', allow_pickle=True).tolist()\n",
        "input['x'] -=input['x'].mean(axis=0)\n",
        "input['x'] /=input['x'].std(axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-jrz0zfaSsp"
      },
      "source": [
        "settings['lambda2a'] = 1.0\n",
        "settings['lambda2b'] = 20.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "imRcT5lGkPIh"
      },
      "source": [
        "tf.reset_default_graph()\n",
        "seed(42)\n",
        "tf.random.set_random_seed(seed = 42)\n",
        "hmf = CanonicalHRFMatrixFactorizationFast(settings)\n",
        "hmf.fit(input)\n",
        "out = hmf.get_params(input)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RInNBWfSJ19i"
      },
      "source": [
        "print(out.keys())\n",
        "print(input.keys())\n",
        "print(settings.keys())\n",
        "print(out['h'].shape)\n",
        "print(np.min(input['GM']),np.max(input['GM']))\n",
        "dims = settings['dims']\n",
        "affine = np.array([[   4.,   -0.,   -0.,  -94.],\n",
        "                [  -0.,    4.,   -0., -130.],\n",
        "                [   0.,    0.,    4.,  -76.],\n",
        "                [   0.,    0.,    0.,    1.]])\n",
        "spatialmodes = nib.Nifti1Image(out['h'].T.reshape(dims[0],dims[1],dims[2],-1), affine=affine)\n",
        "temporalmodes = out['neural']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PyaIRL_cNU_2"
      },
      "source": [
        "from nilearn.plotting import plot_glass_brain\n",
        "from nilearn.image import index_img\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig = plt.figure(figsize=(30,120))\n",
        "comps = [i for i in range(temporalmodes.shape[0])]#[1,2,9,11,13,35,36]\n",
        "grid = plt.GridSpec(len(comps), 6, wspace=0.4, hspace=0.3)\n",
        "for idx,comp in enumerate(comps):\n",
        "  spatial_window = fig.add_subplot(grid[idx, 0])\n",
        "  temporal_window = fig.add_subplot(grid[idx, 1:])\n",
        "  plot_glass_brain(index_img(spatialmodes,comp), axes=spatial_window, title=idx)\n",
        "  temporal_window.plot(temporalmodes[comp,:4*104])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4UTH_bbnYsG9"
      },
      "source": [
        "from nilearn.plotting import plot_glass_brain\n",
        "from nilearn.image import index_img\n",
        "import matplotlib.pyplot as plt\n",
        "fig = plt.figure(figsize=(30,20))\n",
        "comps = [1,13,17,2,22,36,20]\n",
        "grid = plt.GridSpec(len(comps), 6, wspace=0.4, hspace=0.3)\n",
        "for idx,comp in enumerate(comps):\n",
        "  spatial_window = fig.add_subplot(grid[idx, 0])\n",
        "  temporal_window = fig.add_subplot(grid[idx, 1:])\n",
        "  plot_glass_brain(index_img(spatialmodes,comp), axes=spatial_window, title=idx)\n",
        "  temporal_window.plot(temporalmodes[comp,:4*104])\n",
        "\n",
        "fig.savefig('networks.png')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}